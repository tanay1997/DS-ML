{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from scipy.sparse import find\n",
    "\n",
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['talk.religion.misc','comp.graphics','sci.space']\n",
    "\n",
    "num_categories = len(categories)\n",
    "\n",
    "#Loading training data\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "#Loading testing data\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Loading the class labels for training and testing data\n",
    "\n",
    "y_train, y_test = data_train.target, data_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contatins \n",
      " 1554 train documents, \n",
      " 1034 test documents.\n"
     ]
    }
   ],
   "source": [
    "# Total number of documents in train and test datasets\n",
    "\n",
    "num_train = len(data_train.target)\n",
    "num_test = len(data_test.target)\n",
    "\n",
    "print(\"Dataset contatins \\n \"\n",
    "       +str(num_train)+\" train documents, \\n \"\n",
    "       + str(num_test) + \" test documents.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: nicho@vnet.IBM.COM (Greg Stewart-Nicholls)\\nSubject: Re: Biosphere II\\nReply-To: nicho@vnet.ibm.com\\nDisclaimer: This posting represents the poster's views, not those of IBM\\nNews-Software: UReply 3.1\\nX-X-From: nicho@vnet.ibm.com\\n            <1q1kia$gg8@access.digex.net>\\nLines: 18\\n\\nIn <1q1kia$gg8@access.digex.net> Pat writes:\\n>In article <19930408.043740.516@almaden.ibm.com> nicho@vnet.ibm.com writes:\\n>>In <1q09ud$ji0@access.digex.net> Pat writes:\\n>>>Why is everyone being so critical of B2?\\n>> Because it's bogus science, promoted as 'real' science.\\n>It seems to me, that it's sorta a large engineering project more\\n>then a science project.\\n  Bingo.\\n>B2 is not bench science,  but rather a large scale attempt to\\n>re-create a series of micro-ecologies.   what's so eveil about this?\\n Nothing evil at all. There's no actual harm in what they're doing, only\\nhow they represent it.\\n\\n -----------------------------------------------------------------\\n .sig files are like strings ... every yo-yo's got one.\\n\\nGreg Nicholls ... nicho@vnet.ibm.com (business) or\\n                  nicho@olympus.demon.co.uk (private)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(data_train.data + data_test.data)\n",
    "x_train = vectorizer.transform(data_train.data)\n",
    "x_test = vectorizer.transform(data_test.data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = np.where(y_train == 0)\n",
    "class1 = np.where(y_train == 1)\n",
    "class2 = np.where(y_train == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x_train[class0]\n",
    "x1 = x_train[class1]\n",
    "x2 = x_train[class2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0 = np.where(x0.toarray()>0)\n",
    "N1 = np.where(x1.toarray()>0)\n",
    "N2 = np.where(x2.toarray()>0)\n",
    "\n",
    "n0 = x0[N0]\n",
    "n1 = x1[N1]\n",
    "n2 = x2[N2]\n",
    "\n",
    "Z0 = np.asarray(n0).sum(axis=1)\n",
    "Z1 = np.asarray(n1).sum(axis=1)\n",
    "Z2 = np.asarray(n2).sum(axis=1)\n",
    "\n",
    "\n",
    "NC = [Z0, Z1, Z2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.zeros((num_categories,x_train.shape[1]))\n",
    "\n",
    "\n",
    "for i in range(x0.shape[1]):\n",
    "    c[0,i] = np.asarray(x0[:,i].toarray()).sum(axis=0)        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x0.shape[1]):\n",
    "    c[1,i] = np.asarray(x1[:,i].toarray()).sum(axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x0.shape[1]):\n",
    "    c[2,i] = np.asarray(x2[:,i].toarray()).sum(axis=0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiNB_train(x_train,y_train, alpha):\n",
    "    prior = np.bincount(y_train)/num_train\n",
    "    theta = np.zeros((num_categories,x_train.shape[1]))\n",
    "    for j in range (num_categories):\n",
    "        for i in range(x_train.shape[1]):\n",
    "            theta[j,i] = (c[j,i] + alpha)/(NC[j] + (V*alpha)) \n",
    "        \n",
    "    return(theta, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, prior = MultiNB_train(x_train,y_train,alpha = 0.58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiNB_classify(x_test_sample, theta, prior):\n",
    "    \n",
    "    \n",
    "        id = np.where(x_test_sample.toarray() > 0)\n",
    "        p = x_test_sample[id]\n",
    "       \n",
    "        r0 = np.log(theta[0,id[1]])\n",
    "        r1 = np.log(theta[1,id[1]])\n",
    "        r2 = np.log(theta[2,id[1]])\n",
    "        r = np.matrix([r0, r1, r2])\n",
    "        g = np.matmul(r, p.transpose())\n",
    "        P = g.sum(axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        P0 = np.log(prior[0])+P[0]\n",
    "        P1 = np.log(prior[1])+P[1]\n",
    "        P2 = np.log(prior[2])+P[2]\n",
    "        u = np.array([P0, P1, P2])\n",
    "        pred_class = np.argmax(u)\n",
    "\n",
    "    \n",
    "\n",
    "        return pred_class\n",
    "    \n",
    "   \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class:0\n",
      "actual class:0\n"
     ]
    }
   ],
   "source": [
    "pred_class = MultiNB_classify(x_test.getrow(0),theta, prior)\n",
    "\n",
    "print(\"predicted class:\" + str(pred_class))\n",
    "print(\"actual class:\" + str(y_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(num_test):\n",
    "    pred_class = MultiNB_classify(x_test.getrow(i),theta=theta, prior= prior)\n",
    "    y_pred.append(pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.958\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.96       389\n",
      "          1       0.96      0.95      0.96       394\n",
      "          2       0.97      0.96      0.96       251\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"accuracy: %0.3f\" % score)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A good alpha value is between 0.4 to 0.7\n"
     ]
    }
   ],
   "source": [
    "print('A good alpha value is between 0.4 to 0.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
